{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a7af21e-0401-4d1a-ae85-3ad47efb1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "# Always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload\n",
    "\n",
    "# %%capture --no-display\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numba\n",
    "import cupy as cp\n",
    "from numba import cuda, prange\n",
    "from numba.cuda import random as cuda_random\n",
    "from numba import jit, njit, vectorize\n",
    "from numba.core.errors import NumbaPerformanceWarning\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', category=NumbaPerformanceWarning)\n",
    "import GPUtil\n",
    "\n",
    "\n",
    "from src.DDM import *\n",
    "from src.IAM import *\n",
    "from src.dynamic_parameters import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86145608-61ba-42c8-bd65-5382d69619f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU compute capability:  (6, 1)\n",
      "GPU total number of Streaming Multiprocessors (SM):  20\n",
      "GPU total number of cores per SMs:  128\n",
      "total cores:  2560\n",
      "\n",
      " Deciding which execution configuration to use is not easy, and the choice should be driven by performance analysis. However, here are some basic rules to get started:\n",
      "    - The number of blocks in the grid should be larger than the number of Streaming Multiprocessors on the GPU, typically 2 to 4 times larger.\n",
      "    - The number of threads per block should be a multiple of 32, typically between 128 and 512. \n",
      "256\n"
     ]
    }
   ],
   "source": [
    "# Functions\n",
    "\n",
    "def get_gpu_info():       \n",
    "    ''' Gathers GPU information using Numba package\n",
    "    Returns:\n",
    "    num_sm: Number of total Streaming Multiprocessors on GPU\n",
    "    num_cores_per_sm: Number of total SMs on GPU\n",
    "    '''\n",
    "    from numba import cuda\n",
    "    cc_cores_per_SM_dict = {\n",
    "        (2,0) : 32,  (2,1) : 48,\n",
    "        (3,0) : 192, (3,5) : 192, (3,7) : 192,\n",
    "        (5,0) : 128, (5,2) : 128,\n",
    "        (6,0) : 64,  (6,1) : 128,\n",
    "        (7,0) : 64,  (7,5) : 64, \n",
    "        (8,0) : 64,  (8,6) : 128\n",
    "        }\n",
    "\n",
    "    device = cuda.get_current_device()\n",
    "    num_sm = getattr(device, 'MULTIPROCESSOR_COUNT')\n",
    "    my_cc = device.compute_capability\n",
    "    num_cores_per_sm = cc_cores_per_SM_dict.get(my_cc)\n",
    "    total_cores = num_cores_per_sm*num_sm\n",
    "    print(\"GPU compute capability: \" , my_cc)\n",
    "    print(\"GPU total number of Streaming Multiprocessors (SM): \" , num_sm)\n",
    "    print(\"GPU total number of cores per SMs: \" , num_cores_per_sm)\n",
    "    print(\"total cores: \" , total_cores)\n",
    "    print('''\\n Deciding which execution configuration to use is not easy, and the choice should be driven by performance analysis. However, here are some basic rules to get started:\n",
    "    - The number of blocks in the grid should be larger than the number of Streaming Multiprocessors on the GPU, typically 2 to 4 times larger.\n",
    "    - The number of threads per block should be a multiple of 32, typically between 128 and 512. ''')   \n",
    "    \n",
    "    return num_sm, num_cores_per_sm\n",
    "\n",
    "num_sm, num_cores_per_sm = get_gpu_info()\n",
    "\n",
    "print(2*(num_cores_per_sm//32)*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b04d82dd-350b-41df-aded-373c108940c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [0. 1. 0.] \n",
      " [0. 1. 0.]\n",
      "\n",
      " [1169. 1016.  654.] \n",
      " [1169. 1016.  654.]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "num_choices = 2\n",
    "num_trials = 3\n",
    "num_samples = 2000\n",
    "\n",
    "coherence = np.ones((num_trials,num_samples))*50     # 100\n",
    "coherence[0,0:300] = -50\n",
    "coherence[0,1000:1300] = 150\n",
    "coherence[1,10:350] = -50\n",
    "coherence[1,800:1350] = -150\n",
    "coherence[2,10:350] = -100\n",
    "coherence[2,350:700] = 120\n",
    "\n",
    "starting_point = np.zeros(num_choices, dtype=np.float32)             \n",
    "drift_offset = np.zeros(num_choices, dtype=np.float32)\n",
    "drift_gain = np.float32(10e-5)             # drift gain\n",
    "drift_variability = np.float32(0)      # diffusion variability\n",
    "nondecision_time = np.float32(100)         # Non-decision time (msec)\n",
    "decision_bound = 1\n",
    "bound_rate = 0\n",
    "bound_delay = 0\n",
    "lateral_inhibition = 0.005\n",
    "leak = 0.01\n",
    "neural_ddm = 0.2\n",
    "urgency_signal = False\n",
    "# Dynamic time-dependent variables\n",
    "stimulus = get_unsigned_coherence_matrix(coherence)\n",
    "stimulus_cp= cp.asarray(stimulus)\n",
    "decision_bound_cp = get_time_dependent_bound(decision_bound, bound_rate, bound_delay, stop_time=num_samples)\n",
    "decision_bound = cp.asnumpy(decision_bound_cp)\n",
    "drift_variability_cp = get_time_dependent_variability(drift_variability, time_coefficient=0, stop_time=num_samples)\n",
    "drift_variability = cp.asnumpy(drift_variability_cp)\n",
    "                \n",
    "decision1, reaction_time1 = IAM_cpu_sim(stimulus, starting_point, drift_gain, drift_variability, drift_offset, decision_bound, nondecision_time, lateral_inhibition, leak, neural_ddm, urgency_signal)\n",
    "decision2, reaction_time2 = IAM_gpu_sim(stimulus_cp, starting_point, drift_gain, drift_variability_cp, drift_offset, decision_bound_cp, nondecision_time, lateral_inhibition, leak, neural_ddm, urgency_signal)\n",
    "\n",
    "print(\"\\n\", decision1, \"\\n\", decision2)\n",
    "print(\"\\n\", reaction_time1, \"\\n\", reaction_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9592ee1-8964-4571-86fb-9c2ee13b5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1. -1. -1.] [ 1. -1. -1.]\n",
      "[1100. 1073.  315.] [1100. 1073.  315.]\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "\n",
    "num_choices = 2\n",
    "num_trials = 3\n",
    "num_samples = 2000\n",
    "\n",
    "coherence = np.ones((num_trials,num_samples))*50     # 100\n",
    "coherence[0,0:300] = -50\n",
    "coherence[0,1000:1300] = 150\n",
    "coherence[1,10:350] = -50\n",
    "coherence[1,800:1350] = -150\n",
    "coherence[2,10:350] = -100\n",
    "coherence[2,350:700] = 120\n",
    "\n",
    "starting_point = 0 #np.array(np.zeros(1), dtype=float32)             \n",
    "drift_offset = 0 #np.array(np.zeros(1), dtype=float32)\n",
    "drift_gain = np.float32(5e-5)             # drift gain\n",
    "drift_variability = np.float32(0)#10e-3)      # diffusion variability\n",
    "nondecision_time = np.float32(100)         # Non-decision time (msec)\n",
    "decision_bound = 1\n",
    "bound_rate = 0\n",
    "bound_delay = 0\n",
    "lateral_inhibition = 0\n",
    "leak = 0\n",
    "neural_ddm = 0\n",
    "urgency_signal = False\n",
    "# Dynamic time-dependent variables\n",
    "stimulus = get_unsigned_coherence_matrix(coherence)\n",
    "stimulus_cp= cp.asarray(stimulus)\n",
    "decision_bound_cp = get_time_dependent_bound(decision_bound, bound_rate, bound_delay, stop_time=num_samples)\n",
    "decision_bound = cp.asnumpy(decision_bound_cp)\n",
    "drift_variability_cp = get_time_dependent_variability(drift_variability, time_coefficient=0, stop_time=num_samples)\n",
    "drift_variability = cp.asnumpy(drift_variability_cp)\n",
    "\n",
    "\n",
    "decision1, reaction_time1 = DDM_cpu_sim(stimulus, starting_point, drift_gain, drift_variability, drift_offset, decision_bound, nondecision_time)\n",
    "decision2, reaction_time2 = DDM_gpu_sim(stimulus_cp, starting_point, drift_gain, drift_variability_cp, drift_offset, decision_bound_cp, nondecision_time, urgency_signal)\n",
    "    \n",
    "print(decision1, decision2)\n",
    "print(reaction_time1, reaction_time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a85ad69-a90a-46d9-990d-c41fd28365a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
