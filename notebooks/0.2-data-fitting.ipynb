{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec  # Import for custom grid layout\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from config import dir_config\n",
    "from src.decision_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_dir = Path(dir_config.data.compiled)\n",
    "processed_dir = Path(dir_config.data.processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path(processed_dir, 'sessions_metadata.csv'), 'r') as f:\n",
    "    session_metadata = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pre-allocate lists for session data\n",
    "behavior_df = pd.DataFrame(columns=[\"session_id\", \"prior_direction\", \"GP_trial_num\", \"prob_toRF\", \"signed_coherence\", \"target\", \"choice\", \"outcome\",\"response_time\"])\n",
    "\n",
    "\n",
    "# Process each session\n",
    "for _, session_row in session_metadata.iterrows():\n",
    "\n",
    "    session_id = session_row[\"session_id\"]\n",
    "    prior_direction = \"L\" if (session_row[\"prior_direction\"] == \"toRF\" and session_row[\"RF_side\"] == \"L\") or (session_row[\"prior_direction\"] == \"awayRF\" and session_row[\"RF_side\"] == \"R\") else \"R\"\n",
    "\n",
    "    # Read trial data for each session\n",
    "    trial_data = pd.read_csv(Path(compiled_dir, session_id, f\"{session_id}_trial.csv\"), index_col=None)\n",
    "    GP_trial_data = trial_data[trial_data.task_type == 1].reset_index()\n",
    "\n",
    "\n",
    "    # Get valid indices based on outcomes\n",
    "    valid_idx = np.where((GP_trial_data.outcome >= 0) & (~np.isnan(GP_trial_data.reaction_time.values)))[0]\n",
    "\n",
    "    coherence = GP_trial_data.coherence.values[valid_idx]\n",
    "    target = GP_trial_data.target.values[valid_idx].astype(int)\n",
    "    choices = GP_trial_data.choice.values[valid_idx].astype(int)\n",
    "    outcomes = GP_trial_data.outcome.values[valid_idx].astype(int)\n",
    "\n",
    "    if session_row[\"RF_side\"] == \"L\": # flip target and choice to L/R as 0/1\n",
    "        target = 1 - target\n",
    "        choices = 1 - choices\n",
    "\n",
    "    signed_coherence = coherence * (target * 2 - 1)\n",
    "    GP_trial_num = np.array(GP_trial_data.trial_number)[valid_idx]\n",
    "    prob_toRF = np.array(GP_trial_data.prob_toRF)[valid_idx]\n",
    "\n",
    "    # Check for NaNs or missing values\n",
    "    if np.isnan(coherence).any():\n",
    "        print(f\"Warning: NaNs found in coherence for session {session_id}\")\n",
    "    if np.isnan(GP_trial_data.reaction_time.values[valid_idx]).any():\n",
    "        print(f\"Warning: NaNs found in reaction_time for session {session_id}\")\n",
    "    if pd.isnull(target).any():\n",
    "        print(f\"Warning: Missing target values for session {session_id}\")\n",
    "    if pd.isnull(choices).any():\n",
    "        print(f\"Warning: Missing choice values for session {session_id}\")\n",
    "    if pd.isnull(outcomes).any():\n",
    "        print(f\"Warning: Missing outcome values for session {session_id}\")\n",
    "\n",
    "    behavior_df = pd.concat([behavior_df, pd.DataFrame({\n",
    "        \"session_id\": session_id,\n",
    "        \"prior_direction\": prior_direction,\n",
    "        \"GP_trial_num\": GP_trial_num,\n",
    "        \"prob_toRF\": prob_toRF,\n",
    "        \"signed_coherence\": signed_coherence, # range[-100,100]\n",
    "        \"target\": target,\n",
    "        \"choice\": choices,\n",
    "        \"outcome\": outcomes,\n",
    "        \"rt\": GP_trial_data.reaction_time.values[valid_idx]/1000 # in sec\n",
    "    })], ignore_index=True)\n",
    "\n",
    "behavior_df['prior_block'] = np.where(behavior_df['prob_toRF'] == 50, 'equal', 'unequal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_options = {\n",
    "    'maxiter': 1000,\n",
    "    'maxls': 50,\n",
    "    'ftol': 1e-6,\n",
    "    'gtol': 1e-4,\n",
    "    'disp': False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['210126_GP_JP', '210205_GP_JP', '210210_GP_JP'], dtype=object),\n",
       " array(['210211_GP_JP', '210217_GP_JP', '210224_GP_JP'], dtype=object),\n",
       " array(['210302_GP_JP', '210305_GP_JP', '210311_GP_JP'], dtype=object),\n",
       " array(['210312_GP_JP', '210315_GP_JP', '210316_GP_JP'], dtype=object),\n",
       " array(['210317_GP_JP', '210318_GP_JP', '210323_GP_JP'], dtype=object),\n",
       " array(['210413_GP_JP', '210524_GP_JP', '210525_GP_JP'], dtype=object),\n",
       " array(['210528_GP_JP', '210601_GP_JP', '210602_GP_JP'], dtype=object),\n",
       " array(['210603_GP_JP', '210608_GP_JP', '210609_GP_JP'], dtype=object),\n",
       " array(['210708_GP_JP', '240625_GP_TZ', '240627_GP_TZ'], dtype=object),\n",
       " array(['240710_GP_TZ', '240805_GP_TZ', '240809_GP_TZ'], dtype=object),\n",
       " array(['240814_GP_TZ', '240828_GP_TZ', '240903_GP_TZ'], dtype=object),\n",
       " array(['241002_GP_TZ', '241129_GP_TZ', '241130_GP_TZ'], dtype=object),\n",
       " array(['241209_GP_TZ', '241211_GP_TZ', '241216_GP_TZ'], dtype=object),\n",
       " array(['241217_GP_TZ', '241223_GP_TZ', '241227_GP_TZ'], dtype=object),\n",
       " array(['241230_GP_TZ', '250108_GP_TZ', '250109_GP_TZ'], dtype=object)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# break sessions into 5 batches for fitting\n",
    "n_batches = 15\n",
    "session_ids = behavior_df['session_id'].unique()\n",
    "batches = np.array_split(session_ids, n_batches)\n",
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_leak = False\n",
    "enable_time_dependence = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_leak=False\n",
    "enable_time_dependence = False\n",
    "for idx_batch, batch in enumerate(batches):\n",
    "    models, results = [], []\n",
    "    for session_id in batch:\n",
    "        print(f\"Fitting session {session_id}...\")\n",
    "        data = behavior_df[(behavior_df.session_id == session_id)]\n",
    "        data = data[[\"signed_coherence\", \"choice\", \"rt\", \"prior_block\"]].reset_index(drop=True)\n",
    "        data[\"choice\"] = data[\"choice\"].astype(int)\n",
    "\n",
    "        # # Get stimulus length\n",
    "        stimulus_length = int(np.max(data[\"rt\"]) * 1000)\n",
    "        stimulus = np.tile(data[\"signed_coherence\"].to_numpy().reshape(-1, 1), (1, stimulus_length)) / 100  # range[-1,1]\n",
    "\n",
    "        model = DecisionModel(enable_leak=enable_leak, enable_time_dependence=enable_time_dependence, device=\"cuda\")\n",
    "\n",
    "        result = model.fit(data, stimulus, optimizer_options=optimizer_options)\n",
    "\n",
    "        models.append(model)\n",
    "        results.append(result)\n",
    "        print(f\"Finished fitting session {session_id}. Optimizer success: {result.success}. Message: {result.message}\")\n",
    "\n",
    "    break\n",
    "    # with open(Path(processed_dir, f\"ddm_batch_{idx_batch}_fit.pkl\"), \"wb\") as f:\n",
    "    #     pickle.dump({\"models\": models, \"results\": results, \"session_ids\": batch}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading results for batch 0...\n",
      "Loading results for batch 1...\n",
      "Loading results for batch 2...\n",
      "Loading results for batch 3...\n"
     ]
    }
   ],
   "source": [
    "model_results = {}\n",
    "for batch_idx in range(4):\n",
    "    print(f\"Loading results for batch {batch_idx}...\")\n",
    "    with open(Path(processed_dir, f'ddm_batch_{batch_idx}_fit.pkl'), 'rb') as f:\n",
    "        batch_data = pickle.load(f)\n",
    "    for session_id, model, result in zip(batch_data['session_ids'], batch_data['models'], batch_data['results']):\n",
    "        model_results[session_id] = {'model': model, 'result': result}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_results.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for session in model_results.keys():\n",
    "    params.append(model_results[session][\"result\"].x)\n",
    "params = np.array(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_params = np.mean(params, axis=0)\n",
    "std_params = np.std(params, axis=0)\n",
    "param_names = model_results[session][\"model\"].all_params.keys()\n",
    "param_bounds = model_results[session][\"model\"].all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_name, mean_param, std_param in zip(param_names, mean_params, std_params):\n",
    "    bound = model_results[session][\"model\"].all_params[param_name][1]\n",
    "    plt.bar(param_name, mean_param, label=param_name)\n",
    "    plt.errorbar(param_name, mean_param, yerr=std_param, fmt='o', color='r')\n",
    "    plt.ylim(bound)\n",
    "    plt.title(f'Parameter: {param_name}, Mean: {mean_param:.4f}, Bounds: {bound}')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session_idx, session in enumerate(np.unique(behavior_df.session_id)):\n",
    "    print(f\"Fitting session {session}\")\n",
    "    data = behavior_df[(behavior_df.session_id == session)]\n",
    "    data = data[[\"signed_coherence\", \"choice\", \"rt\", \"prior_block\"]]\n",
    "    data['choice'] = data['choice'].astype(int)\n",
    "\n",
    "    # # Get stimulus length\n",
    "    stimulus_length = int(np.max(data[\"rt\"])*1000)\n",
    "    stimulus = np.tile(data[\"signed_coherence\"].to_numpy().reshape(-1, 1), (1, stimulus_length))/100  # range[-1,1]\n",
    "    plot_ddm_fit(model_results[session][\"model\"], data, stimulus, model_results[session][\"result\"], enable_leak=enable_leak, enable_time_dependence=enable_time_dependence)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simulate_ddm(idx_prior, model, result, stimulus, enable_leak=enable_leak, enable_time_dependence=enable_time_dependence):\n",
    "    ddm = DriftDiffusionSimulator()\n",
    "    # Map params into simulator\n",
    "    for name, value in zip(model.all_params, result.x):\n",
    "        if name.endswith(\"_1\") and idx_prior == 0:\n",
    "            base_name = name[:-2]\n",
    "            setattr(ddm, base_name, value)\n",
    "        elif name.endswith(\"_2\") and idx_prior == 1:\n",
    "            base_name = name[:-2]\n",
    "            setattr(ddm, base_name, value)\n",
    "        else:\n",
    "            setattr(ddm, name, value)\n",
    "\n",
    "        if name == \"leak_rate\" and not enable_leak:\n",
    "            setattr(ddm, name, 0.0)\n",
    "        if name == \"time_constant\" and not enable_time_dependence:\n",
    "            setattr(ddm, name, 0.0)\n",
    "\n",
    "        if (name.endswith(\"_1\") and idx_prior == 0) or (name.endswith(\"_2\") and idx_prior == 1):\n",
    "            print(f\"{base_name}: {getattr(ddm, base_name)}\")\n",
    "        elif name.endswith(\"_1\") or name.endswith(\"_2\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"{name}: {getattr(ddm, name)}\")\n",
    "\n",
    "    # Simulate trials\n",
    "    rt, choice, dv = ddm.simulate_trials(stimulus)\n",
    "\n",
    "    # Create DataFrame of simulated data\n",
    "    model_sim = pd.DataFrame(\n",
    "        {\n",
    "            \"signed_coherence\": stimulus[:,0]*100,\n",
    "            \"choice\": choice.flatten(),\n",
    "            \"rt\": rt.flatten(),\n",
    "        }\n",
    "    )\n",
    "    return model_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ddm_fit(model_sim, data):\n",
    "    # Get psychometric and chronometric data for both real and simulated data\n",
    "    x_data, y_data = get_psychometric_data(data)\n",
    "    _, rt_median, rt_mean, rt_sd, _ = get_chronometric_data(data)\n",
    "    x_model, y_model = get_psychometric_data(model_sim)\n",
    "    _, rt_median_model, rt_mean_model, rt_sd_model, _ = get_chronometric_data(model_sim)\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    gs = gridspec.GridSpec(2, 2)\n",
    "\n",
    "    # Psychometric plot (proportion choice)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.plot(x_data, y_data, \"o\", color=\"k\", label=\"data\")\n",
    "    ax1.plot(x_model, y_model, \"o\", color=\"b\", label=\"model\")\n",
    "    ax1.set_ylim(-0.1, 1.1)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Chronometric plot (RT means)\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.plot(x_data, rt_mean, \"o\", color=\"k\", label=\"data\")\n",
    "    ax2.fill_between(x_data, rt_mean - rt_sd, rt_mean + rt_sd, color=\"k\", alpha=0.2)\n",
    "    ax2.fill_between(x_model, rt_mean_model - rt_sd_model, rt_mean_model + rt_sd_model, color=\"b\", alpha=0.2)\n",
    "    ax2.plot(x_model, rt_mean_model, \"o\", color=\"b\", label=\"model\", markersize=8)\n",
    "    ax2.legend()\n",
    "\n",
    "    # ax3 = fig.add_subplot(gs[1, :])\n",
    "    # ax3.plot(dv.T, color=\"k\", alpha=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print proportion of invalid trials (NaN choices)\n",
    "    print(\"Proportion of invalid trials:\", np.mean(np.isnan(model_sim[\"choice\"])))\n",
    "\n",
    "    # return model_sim, ddm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting session 210126_GP_JP\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prior \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munequal\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     11\u001b[0m     prior_stimulus \u001b[38;5;241m=\u001b[39m stimulus[data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprior_block\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m prior]\n\u001b[0;32m---> 12\u001b[0m     model_sim \u001b[38;5;241m=\u001b[39m simulate_ddm(\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prior \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequal\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m, \u001b[43mmodels\u001b[49m[session_idx], results[session_idx], prior_stimulus, enable_leak\u001b[38;5;241m=\u001b[39menable_leak, enable_time_dependence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Prior: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprior\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     15\u001b[0m     plot_ddm_fit(model_sim, data[data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprior_block\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m prior])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "for session_idx, session in enumerate(np.unique(behavior_df.session_id)):\n",
    "    print(f\"Fitting session {session}\")\n",
    "    data = behavior_df[(behavior_df.session_id == session)]\n",
    "    data = data[[\"signed_coherence\", \"choice\", \"rt\", \"prior_block\"]]\n",
    "    data[\"choice\"] = data[\"choice\"].astype(int)\n",
    "\n",
    "    # # Get stimulus length\n",
    "    stimulus_length = int(np.max(data[\"rt\"]) * 1000)\n",
    "    stimulus = np.tile(data[\"signed_coherence\"].to_numpy().reshape(-1, 1), (1, stimulus_length)) / 100  # range[-1,1]\n",
    "    for prior in [\"equal\", \"unequal\"]:\n",
    "        prior_stimulus = stimulus[data[\"prior_block\"] == prior]\n",
    "        model_sim = simulate_ddm(0 if prior == \"equal\" else 1, models[session_idx], results[session_idx], prior_stimulus, enable_leak=enable_leak, enable_time_dependence=True)\n",
    "        print(f\"Session: {session}, Prior: {prior}\")\n",
    "\n",
    "        plot_ddm_fit(model_sim, data[data[\"prior_block\"] == prior])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for session_idx, session in enumerate(np.unique(behavior_df.session_id)):\n",
    "    print(f\"Fitting session {session}\")\n",
    "    data = behavior_df[(behavior_df.session_id == session)]\n",
    "    data = data[[\"signed_coherence\", \"choice\", \"rt\", \"prior_block\"]]\n",
    "    data[\"choice\"] = data[\"choice\"].astype(int)\n",
    "\n",
    "    # # Get stimulus length\n",
    "    stimulus_length = int(np.max(data[\"rt\"]) * 1000)\n",
    "    stimulus = np.tile(data[\"signed_coherence\"].to_numpy().reshape(-1, 1), (1, stimulus_length)) / 100  # range[-1,1]\n",
    "    for prior in [\"equal\", \"unequal\"]:\n",
    "        prior_stimulus = stimulus[data[\"prior_block\"] == prior]\n",
    "        model_sim = simulate_ddm(0 if prior == \"equal\" else 1,\n",
    "                                 model_results[session][\"model\"],\n",
    "                                 model_results[session][\"result\"],\n",
    "                                 prior_stimulus,\n",
    "                                 enable_leak=enable_leak,\n",
    "                                 enable_time_dependence=False)\n",
    "        print(f\"Session: {session}, Prior: {prior}\")\n",
    "\n",
    "        plot_ddm_fit(model_sim, data[data[\"prior_block\"] == prior])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
